{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SalaryDataset:\n",
    "    def __init__(self, csv_file):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        print(\"Initial data shape:\", self.data.shape)\n",
    "        print(\"Initial salary range:\", self.data['Salary'].min(), \"-\", self.data['Salary'].max())\n",
    "        \n",
    "        self.preprocess_data()\n",
    "        \n",
    "    def preprocess_data(self):\n",
    "        print(\"\\nMissing values before cleaning:\")\n",
    "        print(self.data.isnull().sum())\n",
    "        \n",
    "        numeric_columns = ['Age', 'Years of Experience', 'Salary']\n",
    "        categorical_columns = ['Gender', 'Education Level', 'Job Title']\n",
    "        \n",
    "        for col in numeric_columns:\n",
    "            self.data[col] = pd.to_numeric(self.data[col], errors='coerce')\n",
    "            self.data[col] = self.data[col].fillna(self.data[col].median())\n",
    "        \n",
    "        for col in categorical_columns:\n",
    "            self.data[col] = self.data[col].astype(str)\n",
    "            self.data[col] = self.data[col].fillna(self.data[col].mode()[0])\n",
    "        \n",
    "        print(\"\\nMissing values after cleaning:\")\n",
    "        print(self.data.isnull().sum())\n",
    "\n",
    "        self.data['Education Level'] = pd.Categorical(self.data['Education Level']).codes\n",
    "        self.data['Experience_Education'] = (\n",
    "            self.data['Years of Experience'] * \n",
    "            self.data['Education Level']\n",
    "        )\n",
    "        \n",
    "        Q1 = self.data['Salary'].quantile(0.25)\n",
    "        Q3 = self.data['Salary'].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "        self.data = self.data[\n",
    "            (self.data['Salary'] >= lower_bound) & \n",
    "            (self.data['Salary'] <= upper_bound)\n",
    "        ]\n",
    "        \n",
    "        X_numeric = self.data[['Age', 'Years of Experience', 'Experience_Education']].values\n",
    "        X_categorical = self.data[categorical_columns]\n",
    "        \n",
    "        self.numeric_transformer = RobustScaler(quantile_range=(1, 99))\n",
    "        self.categorical_transformer = OneHotEncoder(\n",
    "            drop='first', \n",
    "            sparse_output=False, \n",
    "            handle_unknown='ignore'\n",
    "        )\n",
    "        \n",
    "        X_numeric_scaled = self.numeric_transformer.fit_transform(X_numeric)\n",
    "        \n",
    "        X_categorical_encoded = self.categorical_transformer.fit_transform(X_categorical)\n",
    "        \n",
    "        self.X = np.hstack([X_numeric_scaled, X_categorical_encoded])\n",
    "        \n",
    "        self.salary_scaler = RobustScaler(quantile_range=(1, 99))\n",
    "        self.y = self.salary_scaler.fit_transform(\n",
    "            self.data['Salary'].values.reshape(-1, 1)\n",
    "        ).ravel()\n",
    "        \n",
    "        self.X = self.X.astype(np.float32)\n",
    "        self.y = self.y.astype(np.float32)\n",
    "        \n",
    "        print(\"\\nProcessed data information:\")\n",
    "        print(\"Features shape:\", self.X.shape)\n",
    "        print(\"Target shape:\", self.y.shape)\n",
    "        \n",
    "        if np.any(np.isnan(self.X)) or np.any(np.isnan(self.y)):\n",
    "            raise ValueError(\"NaN values found in processed data\")\n",
    "    \n",
    "    def get_data(self):\n",
    "        return torch.FloatTensor(self.X), torch.FloatTensor(self.y)\n",
    "    \n",
    "    def inverse_transform_salary(self, scaled_salary):\n",
    "        return self.salary_scaler.inverse_transform(scaled_salary.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SalaryPredictor(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(SalaryPredictor, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, 16)\n",
    "        self.fc5 = nn.Linear(16, 1)\n",
    "        \n",
    "        self.res1 = nn.Linear(input_size, 64)\n",
    "        self.res2 = nn.Linear(64, 32)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.bn3 = nn.BatchNorm1d(32)\n",
    "        self.bn4 = nn.BatchNorm1d(16)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "        self._initialize_weights()\n",
    "        \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        identity1 = self.res1(x)\n",
    "        \n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = x + identity1 \n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        identity2 = self.res2(x)\n",
    "        \n",
    "        x = F.relu(self.bn3(self.fc3(x)))\n",
    "        x = x + identity2 \n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = F.relu(self.bn4(self.fc4(x)))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc5(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X, y, epochs=300, lr=0.001, batch_size=32):\n",
    "    criterion = nn.HuberLoss(delta=1.0) \n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=15, verbose=True)\n",
    "    \n",
    "    \n",
    "    y_binned = pd.qcut(y.numpy(), q=5, labels=False) \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X.numpy(), y.numpy(), test_size=0.2, random_state=42, stratify=y_binned\n",
    "    )\n",
    "    \n",
    "    X_train = torch.FloatTensor(X_train)\n",
    "    X_test = torch.FloatTensor(X_test)\n",
    "    y_train = torch.FloatTensor(y_train)\n",
    "    y_test = torch.FloatTensor(y_test)\n",
    "    \n",
    "    train_data = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    print(\"\\nStarting training:\")\n",
    "    print(f\"Training samples: {len(X_train)}\")\n",
    "    print(f\"Test samples: {len(X_test)}\")\n",
    "    \n",
    "    best_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    patience = 25\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        for batch_X, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs.squeeze(), batch_y)\n",
    "            \n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "        \n",
    "        avg_loss = total_loss / num_batches\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            test_outputs = model(X_test)\n",
    "            test_loss = criterion(test_outputs.squeeze(), y_test)\n",
    "            \n",
    "            y_mean = torch.mean(y_test)\n",
    "            ss_tot = torch.sum((y_test - y_mean) ** 2)\n",
    "            ss_res = torch.sum((y_test - test_outputs.squeeze()) ** 2)\n",
    "            r2 = 1 - (ss_res / ss_tot)\n",
    "            \n",
    "            scheduler.step(test_loss)\n",
    "            \n",
    "            if test_loss < best_loss:\n",
    "                best_loss = test_loss\n",
    "                best_model_state = model.state_dict().copy()\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "            \n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "            \n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                print(f'Epoch [{epoch+1}/{epochs}], '\n",
    "                      f'Train Loss: {avg_loss:.6f}, '\n",
    "                      f'Test Loss: {test_loss.item():.6f}, '\n",
    "                      f'R²: {r2:.4f}')\n",
    "    \n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing data...\n",
      "Initial data shape: (6704, 6)\n",
      "Initial salary range: 350.0 - 250000.0\n",
      "\n",
      "Missing values before cleaning:\n",
      "Age                    2\n",
      "Gender                 2\n",
      "Education Level        3\n",
      "Job Title              2\n",
      "Years of Experience    3\n",
      "Salary                 5\n",
      "dtype: int64\n",
      "\n",
      "Missing values after cleaning:\n",
      "Age                    0\n",
      "Gender                 0\n",
      "Education Level        0\n",
      "Job Title              0\n",
      "Years of Experience    0\n",
      "Salary                 0\n",
      "dtype: int64\n",
      "\n",
      "Processed data information:\n",
      "Features shape: (6704, 206)\n",
      "Target shape: (6704,)\n",
      "\n",
      "Initializing model...\n",
      "\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rishiviswanathan/Desktop/job-salary-prediction/venv/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training:\n",
      "Training samples: 5363\n",
      "Test samples: 1341\n",
      "Epoch [10/300], Train Loss: 0.016978, Test Loss: 0.006661, R²: 0.8350\n",
      "Epoch [20/300], Train Loss: 0.010827, Test Loss: 0.003894, R²: 0.9035\n",
      "Epoch [30/300], Train Loss: 0.008263, Test Loss: 0.003447, R²: 0.9146\n",
      "Epoch [40/300], Train Loss: 0.006778, Test Loss: 0.002613, R²: 0.9353\n",
      "Epoch [50/300], Train Loss: 0.006245, Test Loss: 0.002088, R²: 0.9483\n",
      "Epoch [60/300], Train Loss: 0.005815, Test Loss: 0.002370, R²: 0.9413\n",
      "Epoch [70/300], Train Loss: 0.005647, Test Loss: 0.001607, R²: 0.9602\n",
      "Epoch [80/300], Train Loss: 0.005558, Test Loss: 0.001822, R²: 0.9549\n",
      "Epoch [90/300], Train Loss: 0.005110, Test Loss: 0.001567, R²: 0.9612\n",
      "Epoch [100/300], Train Loss: 0.005207, Test Loss: 0.001543, R²: 0.9618\n",
      "Epoch [110/300], Train Loss: 0.005434, Test Loss: 0.001681, R²: 0.9584\n",
      "Epoch [120/300], Train Loss: 0.004996, Test Loss: 0.001856, R²: 0.9540\n",
      "Epoch [130/300], Train Loss: 0.004976, Test Loss: 0.001632, R²: 0.9596\n",
      "Early stopping at epoch 134\n",
      "\n",
      "Making predictions...\n",
      "\n",
      "Comparison of actual vs predicted salaries:\n",
      "Actual: $90000.00, Predicted: $144858.47, Error: 61.0%\n",
      "Actual: $65000.00, Predicted: $111995.61, Error: 72.3%\n",
      "Actual: $150000.00, Predicted: $151695.78, Error: 1.1%\n",
      "Actual: $60000.00, Predicted: $69787.36, Error: 16.3%\n",
      "Actual: $200000.00, Predicted: $191345.81, Error: 4.3%\n",
      "\n",
      "Average error: 31.0%\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    torch.manual_seed(42)\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    try:\n",
    "        print(\"Loading and preprocessing data...\")\n",
    "        dataset = SalaryDataset('../data/Salary_Data.csv')\n",
    "        X, y = dataset.get_data()\n",
    "        \n",
    "        print(\"\\nInitializing model...\")\n",
    "        model = SalaryPredictor(input_size=X.shape[1])\n",
    "        \n",
    "        print(\"\\nTraining model...\")\n",
    "        model = train_model(model, X, y)\n",
    "        \n",
    "        print(\"\\nMaking predictions...\")\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            print(\"\\nComparison of actual vs predicted salaries:\")\n",
    "            total_error = 0\n",
    "            n_samples = min(5, len(X))\n",
    "            \n",
    "            for i in range(n_samples):\n",
    "                pred = model(X[i:i+1])\n",
    "                actual = dataset.inverse_transform_salary(y[i:i+1].numpy())\n",
    "                predicted = dataset.inverse_transform_salary(pred.numpy())\n",
    "                error_pct = abs(actual[0][0] - predicted[0][0]) / actual[0][0] * 100\n",
    "                total_error += error_pct\n",
    "                print(f\"Actual: ${actual[0][0]:.2f}, Predicted: ${predicted[0][0]:.2f}, Error: {error_pct:.1f}%\")\n",
    "            \n",
    "            print(f\"\\nAverage error: {total_error/n_samples:.1f}%\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        import traceback\n",
    "        print(traceback.format_exc())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to model.pth\n"
     ]
    }
   ],
   "source": [
    "save_path = 'model.pth'\n",
    "torch.save(model.state_dict(), save_path)\n",
    "print(f\"Model saved to {save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
